{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an [jupyter](http://jupyter.org) notebook.\n",
    "Lectures about Python, useful both for beginners and experts, can be found at http://scipy-lectures.github.io."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the notebook by (1) copying this file into a directory, (2) in that directory typing \n",
    "jupyter-notebook\n",
    "and (3) selecting the notebook.\n",
    "\n",
    "***\n",
    "Written By: **Riddhish Bhalodia**\n",
    "***\n",
    "\n",
    "In this exercise, we will learn about different neural network concepts. There are few prerequisites of probability and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is one of the example of a linear discriminant model and used for two-class clustering / separation. In this model the input bector **x** is transformed using a fixed non-linear transformation. So starting from generalized model of linear regression we have\n",
    "\n",
    "$$ y(\\textbf{x}) = \\textbf{w}^T\\phi(\\textbf{x})$$\n",
    "\n",
    "Now in perceptron all we do is pass this linear regression model through a non-linear activation function as follows\n",
    "\n",
    "$$y(\\textbf{x}) = f(\\textbf{w}^T\\phi(\\textbf{x})) \\quad \\quad \\quad (1)$$\n",
    "\n",
    "Here, $f(.)$ is given by \n",
    "$$\n",
    "f(a) = \\left\\{\n",
    "  \\begin{array}{ll}\n",
    "  -1 & \\quad a < 0 \\\\\n",
    "   1 & \\quad a \\geq 0\n",
    "   \\end{array}\n",
    "   \\right.\n",
    "$$\n",
    "\n",
    "Now, as we have two classes $\\mathcal{C}_1$ and $\\mathcal{C}_2$ so we define a target variable t which takes the values +1 and -1 for $\\mathcal{C}_1$ and $\\mathcal{C}_2$ respectively. Now we need to determine the parameters **w**, for that we need to define an error function which we have to minimize.\n",
    "\n",
    "A natural choice for the error function is total number of misclassified patterns, however this causes some problems in the learning algorithm. Hence we propose an alternate error function called the *perceptron criterion* given by \n",
    "\n",
    "$$ E_p(\\textbf{w}) = - \\sum \\limits _{n \\in \\mathcal{M}} \\textbf{w}^T \\phi_n t_n$$\n",
    "\n",
    "Here, $\\mathcal{M}$ denotes the set of all the misclassified patterns, the reasoning behind this functional can be found Christopher M Bishop's book [here](http://www.springer.com/gp/book/9780387310732) :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
